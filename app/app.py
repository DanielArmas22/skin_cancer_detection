# app.py
"""
Aplicaci√≥n principal para el sistema de diagn√≥stico de c√°ncer de piel
"""

import streamlit as st
import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image

# Importar m√≥dulos propios
from config import initialize_page, MCC_COMPARISON_DATA
from model_utils import load_models, predict_image, predict_image_with_debug, predict_image_with_custom_threshold, get_model_info
from preprocessing import preprocess_image
from ui_components import (
    setup_sidebar, display_main_header, display_image_upload_section, display_image_comparison,
    display_diagnosis_results, display_debug_info, display_interpretation, display_model_comparison_table,
    display_consistency_analysis, display_metrics_explanation, display_metrics_in_columns,
    display_mcc_interpretation, display_technical_info, display_medical_disclaimer,
    display_pdf_generation_section, display_mcnemar_results_table, display_statistical_conclusions
)
from data_processor import (
    compare_all_models, analyze_consistency, get_model_metrics,
    create_mcc_comparison_dataframe, format_metrics_for_display
)
from activation_maps import generate_gradcam
from visualization import (
    plot_confusion_matrix, create_metrics_dashboard, create_advanced_metrics_dashboard,
    create_model_comparison_plots, create_mcc_comparison_chart, create_mcnemar_plot
)
from metrics_calculator import perform_mcnemar_comparisons
from pdf_generator_optimized import generate_pdf_report
from translations import get_available_languages, load_translations


def main():
    """Funci√≥n principal de la aplicaci√≥n"""
    # Inicializar la configuraci√≥n de la p√°gina
    initialize_page()
    
    # Configuraci√≥n inicial para traducciones (espa√±ol por defecto)
    available_languages = get_available_languages()
    t = load_translations('es')
    
    # Cargar modelos entrenados
    @st.cache_resource
    def load_models_cached():
        try:
            models = load_models()
            if not models:
                st.error("‚ùå " + t.get('models_load_error', "No se pudieron cargar los modelos entrenados."))
                st.error("üìù " + t.get('models_folder_check', "Aseg√∫rate de que los archivos .h5 est√©n en la carpeta app/models/"))
                return {}
            return models
        except Exception as e:
            st.error(f"‚ùå {t.get('model_load_exception', 'Error al cargar los modelos')}: {str(e)}")
            return {}

    models = load_models_cached()
    model_names = list(models.keys())

    if not model_names:
        st.error("‚ùå " + t.get('no_models_available', "No hay modelos disponibles. Verifica que los modelos entrenados est√©n en app/models/"))
        st.stop()
    
    # Configurar la barra lateral y obtener la configuraci√≥n del usuario
    sidebar_config = setup_sidebar(models, t, available_languages)
    
    # Actualizar las traducciones seg√∫n el idioma seleccionado
    current_lang_code = available_languages[sidebar_config['lang']]
    t = load_translations(current_lang_code)
    
    # Mostrar encabezado principal
    display_main_header(t)
    
    # Secci√≥n de carga de imagen
    uploaded_file = display_image_upload_section(t)
    
    # Procesamiento de la imagen si se sube un archivo
    if uploaded_file is not None:
        # Cargar y mostrar imagen original
        image = Image.open(uploaded_file)
        
        # Preprocesamiento
        processed_image = preprocess_image(np.array(image))
        
        # Mostrar comparaci√≥n de im√°genes
        display_image_comparison(image, processed_image, t)
        
        # Realizar predicci√≥n con el modelo seleccionado
        st.header("üîç " + t.get('diagnosis_results', "Resultados del Diagn√≥stico"))
        
        with st.spinner(t.get('processing_image', "Analizando imagen...")):
            model = models[sidebar_config['selected_model']]
            
            if sidebar_config['debug_mode']:
                # Usar funci√≥n de debug
                diagnosis, confidence_percent, raw_confidence = predict_image_with_debug(model, processed_image)
                
                # Mostrar informaci√≥n de debug
                display_debug_info(processed_image, model, sidebar_config['decision_threshold'], t)
            else:
                # Usar funci√≥n con umbral personalizado
                diagnosis, confidence_percent, raw_confidence = predict_image_with_custom_threshold(
                    model, processed_image, threshold=sidebar_config['decision_threshold']
                )
        
        # Mostrar resultados con mejor dise√±o
        display_diagnosis_results(diagnosis, confidence_percent, raw_confidence, t)
        
        # Interpretaci√≥n de resultados
        display_interpretation(confidence_percent, sidebar_config['confidence_threshold'], diagnosis, t)
        
        # COMPARACI√ìN DE TODOS LOS MODELOS
        st.markdown("---")
        st.subheader("üìä " + t.get('model_comparison', "Comparaci√≥n de Todos los Modelos"))
        st.markdown("Resultados de an√°lisis de la misma imagen con diferentes modelos:")
        
        # Realizar predicciones con todos los modelos
        with st.spinner("Comparando todos los modelos..."):
            comparison_results = compare_all_models(models, processed_image)
        
        # Mostrar tabla de comparaci√≥n
        if comparison_results:
            df_comparison = pd.DataFrame(comparison_results)
            display_model_comparison_table(df_comparison)
            
            # Gr√°ficos de comparaci√≥n
            fig_confianza, fig_tiempo = create_model_comparison_plots(df_comparison)
            if fig_confianza:
                st.pyplot(fig_confianza)
            if fig_tiempo:
                st.pyplot(fig_tiempo)
            
            # An√°lisis de consistencia
            display_consistency_analysis(comparison_results, t)
        
        # MATRIZ DE CONFUSI√ìN Y M√âTRICAS
        st.markdown("---")
        st.subheader("üìä " + t.get('confusion_matrix', "Matriz de Confusi√≥n y M√©tricas"))
        st.markdown("An√°lisis detallado del rendimiento del modelo seleccionado:")
        
        # Obtener m√©tricas del modelo seleccionado
        metrics_data, is_real_data = get_model_metrics(sidebar_config['selected_model'])
        
        if is_real_data:
            st.success(f"‚úÖ **Datos Reales de Entrenamiento**: Mostrando m√©tricas reales del modelo {sidebar_config['selected_model']} en el dataset ISIC 2019")
        else:
            st.warning("‚ö†Ô∏è **Datos Simulados**: Usando datos de ejemplo para demostraci√≥n")
        
        # Mostrar matriz de confusi√≥n
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**üéØ Matriz de Confusi√≥n**")
            fig_cm = plot_confusion_matrix(metrics_data['confusion_matrix'], sidebar_config['selected_model'])
            if fig_cm:
                st.pyplot(fig_cm)
        
        with col2:
            st.markdown("**üìà M√©tricas de Rendimiento Avanzadas**")
            display_metrics_in_columns(metrics_data)
            
            # Interpretaci√≥n de m√©tricas
            st.markdown("**üìã Interpretaci√≥n:**")
            formatted_metrics = format_metrics_for_display(metrics_data)
            st.markdown(f"""
            - **Accuracy**: {metrics_data['accuracy']*100:.1f}% de las predicciones son correctas
            - **Sensitivity**: {metrics_data['sensitivity']*100:.1f}% de los casos malignos son detectados
            - **Specificity**: {metrics_data['specificity']*100:.1f}% de los casos benignos son correctamente identificados
            - **Precision**: {metrics_data['precision']*100:.1f}% de los casos clasificados como malignos son realmente malignos
            - **F1-Score**: {metrics_data['f1_score']*100:.1f}% es el balance entre precisi√≥n y sensibilidad
            - **MCC**: {metrics_data['mcc']:.3f} (Coeficiente de Matthews - balanceado para clases desequilibradas)
            """)
        
        # Dashboard completo de m√©tricas
        st.markdown("---")
        st.subheader("üìä Dashboard Completo de M√©tricas")
        
        fig_dashboard = create_metrics_dashboard(metrics_data, sidebar_config['selected_model'])
        if fig_dashboard:
            st.pyplot(fig_dashboard)
        
        # Visualizaci√≥n de mapas de activaci√≥n
        st.markdown("---")
        st.subheader("üîç Visualizaci√≥n de Mapas de Activaci√≥n")
        st.markdown("Visualizaci√≥n de las regiones de la imagen que m√°s influyeron en el diagn√≥stico:")
        
        with st.spinner("Generando mapa de activaci√≥n..."):
            activation_map = generate_gradcam(model, processed_image)
            if activation_map is not None:
                col1, col2 = st.columns(2)
                with col1:
                    st.image(processed_image, caption="Imagen Procesada", use_column_width=True)
                with col2:
                    st.image(activation_map, caption="Mapa de Activaci√≥n (Grad-CAM)", use_column_width=True)
                st.info("El mapa de calor muestra las regiones que m√°s influyeron en el diagn√≥stico del modelo. Las √°reas rojas y amarillas son las m√°s relevantes.")
            else:
                st.error("No se pudo generar el mapa de activaci√≥n para este modelo.")
        
        # Explicaci√≥n de la matriz de confusi√≥n
        display_metrics_explanation()
        
        # An√°lisis Estad√≠stico Avanzado
        st.markdown("---")
        st.subheader("üî¨ An√°lisis Estad√≠stico Avanzado")
        st.markdown("Incluyendo Coeficiente de Matthews y Pruebas de McNemar:")
        
        # Crear dashboard avanzado con MCC
        fig_advanced = create_advanced_metrics_dashboard(metrics_data, sidebar_config['selected_model'])
        if fig_advanced:
            st.pyplot(fig_advanced)
        
        # Tabla de Resumen MCC y Gr√°fico Comparativo
        st.markdown("---")
        st.subheader("üìä Resumen Comparativo de Coeficientes de Matthews (MCC)")
        st.markdown("Comparaci√≥n de todos los modelos basada en el Coeficiente de Matthews:")
        
        # Crear DataFrame para la tabla
        df_mcc = create_mcc_comparison_dataframe(MCC_COMPARISON_DATA)
        
        # Mostrar tabla con formato mejorado
        col1, col2 = st.columns([3, 2])
        
        with col1:
            st.markdown("**üìã Tabla de Resumen - Coeficientes de Matthews**")
            st.dataframe(df_mcc, use_container_width=True)
        
        with col2:
            display_mcc_interpretation(MCC_COMPARISON_DATA)
        
        # Gr√°fico MCC
        fig_mcc = create_mcc_comparison_chart(MCC_COMPARISON_DATA)
        if fig_mcc:
            st.pyplot(fig_mcc)
        
        # An√°lisis Estad√≠stico - Pruebas de McNemar
        st.markdown("---")
        st.subheader("üî¨ Pruebas Estad√≠sticas de McNemar")
        st.markdown("Comparaci√≥n estad√≠stica entre modelos:")
        
        # Generar resultados de McNemar
        mcnemar_results = perform_mcnemar_comparisons()
        
        # Mostrar tabla de resultados
        display_mcnemar_results_table(mcnemar_results)
        
        # Gr√°fico de p-valores
        fig_mcnemar = create_mcnemar_plot(mcnemar_results)
        if fig_mcnemar:
            st.pyplot(fig_mcnemar)
        
        # Conclusiones estad√≠sticas
        display_statistical_conclusions(mcnemar_results)
        
        # Generar reporte PDF
        generate_pdf = display_pdf_generation_section(t)
        
        if generate_pdf:
            with st.spinner("Generando reporte PDF..."):
                # Preparar datos para el PDF
                plots_data = {
                    'confusion_matrix': fig_cm if 'fig_cm' in locals() else None,
                    'metrics_dashboard': fig_dashboard if 'fig_dashboard' in locals() else None,
                    'advanced_dashboard': fig_advanced if 'fig_advanced' in locals() else None,
                    'comparison_plots': {
                        'Comparacion de Confianza': fig_confianza if 'fig_confianza' in locals() else None,
                        'Velocidad de Inferencia': fig_tiempo if 'fig_tiempo' in locals() else None,
                        'MCC Comparativo': fig_mcc if 'fig_mcc' in locals() else None,
                        'McNemar P-valores': fig_mcnemar if 'fig_mcnemar' in locals() else None
                    }
                }
                
                # Generar PDF
                generate_pdf_report(
                    image=image,
                    diagnosis=diagnosis,
                    confidence_percent=confidence_percent,
                    raw_confidence=raw_confidence,
                    model_name=sidebar_config['selected_model'],
                    model_info=get_model_info(models[sidebar_config['selected_model']]),
                    comparison_results=comparison_results,
                    translations=t,
                    confidence_threshold=sidebar_config['confidence_threshold'],
                    metrics_data=metrics_data,
                    plots_data=plots_data
                )
        
        # Informaci√≥n t√©cnica
        display_technical_info(get_model_info(models[sidebar_config['selected_model']]), t)
        
        # Advertencia m√©dica
        display_medical_disclaimer()


if __name__ == "__main__":
    main()
